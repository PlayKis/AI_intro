{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9520d2",
   "metadata": {},
   "source": [
    "# Лабораторная работа №2\n",
    "\n",
    "ФИО:   \n",
    "Группа: \n",
    "\n",
    "Отправлять можно следующими способами:\n",
    "1. Запушить этот ноутбук в GitHub в репозиторий, где у вас лежат ноутбуки с лабами\n",
    "\n",
    "Deadlines:\n",
    "- Занятие №6\n",
    "\n",
    "Что необходимо сделать:  \n",
    "**В общих чертах просто провести EDA** (но обычно это не бывает просто)\n",
    "## Читайте задание внимательно\n",
    "\n",
    "Исходные данные:\n",
    "1. В [табличке](https://docs.google.com/spreadsheets/d/1NOE0D4JQgD6LbvUqWboUI1TFj4P87ugbqUTDquxlGEI/edit?usp=sharing) необходимо узнать название своего датасета \n",
    "2. Скачать нужны вам данные можно в [Google Drive](https://drive.google.com/drive/folders/1sbsjBsJ_ln0XgXCI9R6s17pvyvApgcwF?usp=sharing)\n",
    "  \n",
    "---\n",
    "Теперь по пунктам, что я от вас жду:  \n",
    "1. **Найти** в таблице (из исходных данных) название своего датасета\n",
    "2. **Описать** кратко постановку задачи, что от вас хотят. Какие есть переменные. Целевое событие непрерывно (предсказываем число от -$\\infty$ до $\\infty$) либо дискретно (предсказываем класс из конечного множества вариантов, например 0 или 1, или какое-то число в диапазоне [0; 10])\n",
    "3. Построить распределение целевой переменной в виде гистограммы, сделать промежуточные выводы (обратите внимание на однородоность распределения и возможный дисбаланс). Посчитайте количество уникальных значений целевой переменной.\n",
    "4. Выведите основные статистики по переменным в датасете (для этого есть готовый метод в pandas, он считает count, min, max, mean, 25%, 50% и пр.). Это делается **одним** методом (вы его знаете).\n",
    "5. Выведите основную информацию по датасету (сколько всего колонок, каких они типов, сколько в них non-null элементов). Это делается **одним** методом (вы его знаете).\n",
    "6. Посчитайте количество пропусков (NaN, Null, null, None) элементов во всех колонках. Предположите, почему эти пропуски могли возникнуть, и как их можно было бы заменить. \n",
    "7. Постройте гистограммы 5 любых признаков (из множества `X`, или как оно изначально у нас называется `data.data`). Если видите какое-то смещение, несимметричность и прочее, опишите это словами в ноутбуке.\n",
    "8. Постройте графики зависимости 5 любых (на ваш выбор) переменных от целевой переменной (если переменных меньше, чем 5, то сделайте столько, сколько получится). Сделайте вывод, можно ли использовать эти переменные для прогнозирования целевой переменной (иначе говоря, есть ли какая-то взаимосвязь между y-переменной и X-переменной)  \n",
    "9. _extra_ (необязательно). Посмотрите на зависимость двух переменных одновременно от целевой переменной. То есть по оси OX должна быть переменная $X_{n}$, по оси OY -- переменная $X_{k}$. И у вас будет две кривые (два облака точек) в разрезе целевой переменной. Либо вы можете построить похожее для категориальных признаков, но необходимо будет прочитать про heatmap. \n",
    "\n",
    "---\n",
    "P.S.  \n",
    "Просьба -- делать каждое задание в отдельных ячейках и с отдельными заголовками (как пункт 1 и 2 в этом ноутбуке) типа  \n",
    "- Заголовок\n",
    "- Ячейки с кодом\n",
    "- Другой заголовок\n",
    "- Другие ячейки с кодом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51062",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406597a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('students_adaptability_level_online_education.csv')\n",
    "print(f\"Размер датасета: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d119028",
   "metadata": {},
   "source": [
    "## 2. Описание постановки задачи\n",
    "\n",
    "**Название датасета:** Students Adaptability Level in Online Education\n",
    "\n",
    "**Постановка задачи:** \n",
    "Необходимо предсказать уровень адаптивности студентов к онлайн-образованию на основе различных характеристик: демографических данных, условий обучения, технических возможностей и других факторов.\n",
    "\n",
    "**Переменные в датасете:**\n",
    "- **Признаки (X):** Gender, Age, Education Level, Institution Type, IT Student, Location, Load-shedding, Financial Condition, Internet Type, Network Type, Class Duration, Self Lms, Device\n",
    "- **Целевая переменная (y):** Adaptivity Level\n",
    "\n",
    "**Тип задачи:** Классификация (дискретная целевая переменная)\n",
    "- Целевая переменная является **дискретной** - предсказываем класс из конечного множества вариантов (Low, Moderate, High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92464d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X = data.drop('Adaptivity Level', axis=1)\n",
    "y = data['Adaptivity Level']\n",
    "\n",
    "print(\"Признаки (X):\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"\\nЦелевая переменная (y): {y.name}\")\n",
    "print(f\"Уникальные значения целевой переменной: {y.unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34931f43",
   "metadata": {},
   "source": [
    "## 3. Распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a611d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество уникальных значений целевой переменной\n",
    "unique_count = y.nunique()\n",
    "print(f\"Количество уникальных значений целевой переменной: {unique_count}\")\n",
    "print(f\"\\nРаспределение значений:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nПроцентное распределение:\")\n",
    "print(y.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Построение гистограммы\n",
    "plt.figure(figsize=(10, 6))\n",
    "y.value_counts().sort_index().plot(kind='bar', color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "plt.title('Распределение целевой переменной (Adaptivity Level)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Уровень адаптивности', fontsize=12)\n",
    "plt.ylabel('Количество студентов', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выводы\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ВЫВОДЫ:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"1. Целевая переменная имеет {unique_count} уникальных значения\")\n",
    "print(\"2. Распределение классов:\")\n",
    "for val, count in y.value_counts().items():\n",
    "    pct = (count / len(y)) * 100\n",
    "    print(f\"   - {val}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "# Проверка на дисбаланс\n",
    "max_class = y.value_counts().max()\n",
    "min_class = y.value_counts().min()\n",
    "imbalance_ratio = max_class / min_class\n",
    "print(f\"\\n3. Соотношение максимального и минимального класса: {imbalance_ratio:.2f}\")\n",
    "if imbalance_ratio > 2:\n",
    "    print(\"   ⚠️ Обнаружен дисбаланс классов!\")\n",
    "else:\n",
    "    print(\"   ✓ Распределение относительно сбалансировано\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4715b3a",
   "metadata": {},
   "source": [
    "## 4. Основные статистики по переменным\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные статистики (describe() работает только для числовых признаков)\n",
    "# В данном датасете все признаки категориальные, поэтому посмотрим на описательные статистики\n",
    "print(\"Описательные статистики для категориальных признаков:\")\n",
    "print(\"=\"*60)\n",
    "for col in X.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(X[col].value_counts())\n",
    "    print(f\"Уникальных значений: {X[col].nunique()}\")\n",
    "\n",
    "# Для числовых признаков (если бы они были) использовали бы:\n",
    "# data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c4571",
   "metadata": {},
   "source": [
    "## 5. Основная информация по датасету\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основная информация о датасете\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2a1dd",
   "metadata": {},
   "source": [
    "## 6. Анализ пропущенных значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет пропущенных значений\n",
    "missing_values = data.isnull().sum()\n",
    "missing_percent = (missing_values / len(data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Колонка': missing_values.index,\n",
    "    'Количество пропусков': missing_values.values,\n",
    "    'Процент пропусков': missing_percent.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Количество пропусков'] > 0].sort_values('Количество пропусков', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Пропущенные значения:\")\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"✓ Пропущенных значений не обнаружено!\")\n",
    "    print(\"\\nПроверка всех возможных вариантов пропусков:\")\n",
    "    print(f\"NaN: {data.isna().sum().sum()}\")\n",
    "    print(f\"Null (строки): {data.isnull().sum().sum()}\")\n",
    "    print(f\"None: {(data == None).sum().sum()}\")\n",
    "    print(f\"Пустые строки: {(data == '').sum().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"АНАЛИЗ ПРОПУСКОВ:\")\n",
    "print(\"=\"*60)\n",
    "if len(missing_df) == 0:\n",
    "    print(\"В датасете отсутствуют пропущенные значения.\")\n",
    "    print(\"Это может означать, что:\")\n",
    "    print(\"1. Данные были предварительно обработаны и очищены\")\n",
    "    print(\"2. Данные собирались в контролируемых условиях\")\n",
    "    print(\"3. Пропуски были заполнены до публикации датасета\")\n",
    "else:\n",
    "    print(\"Обнаружены пропуски в следующих колонках:\")\n",
    "    for idx, row in missing_df.iterrows():\n",
    "        print(f\"\\n{row['Колонка']}: {row['Количество пропусков']} ({row['Процент пропусков']:.2f}%)\")\n",
    "        print(\"Возможные причины:\")\n",
    "        print(\"  - Нежелание респондентов отвечать на вопрос\")\n",
    "        print(\"  - Технические проблемы при сборе данных\")\n",
    "        print(\"  - Неприменимость вопроса к некоторым случаям\")\n",
    "        print(\"\\nСпособы заполнения:\")\n",
    "        print(\"  - Для категориальных: мода (наиболее частое значение)\")\n",
    "        print(\"  - Для числовых: медиана или среднее\")\n",
    "        print(\"  - Создание отдельной категории 'Unknown'\")\n",
    "        print(\"  - Удаление строк с пропусками (если их мало)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df03794",
   "metadata": {},
   "source": [
    "## 7. Гистограммы признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем 5 признаков для анализа\n",
    "selected_features = ['Gender', 'Age', 'Education Level', 'Financial Condition', 'Device']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(selected_features):\n",
    "    value_counts = X[feature].value_counts()\n",
    "    axes[i].bar(range(len(value_counts)), value_counts.values, color=plt.cm.Set3(range(len(value_counts))))\n",
    "    axes[i].set_title(f'Распределение: {feature}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Значения', fontsize=10)\n",
    "    axes[i].set_ylabel('Количество', fontsize=10)\n",
    "    axes[i].set_xticks(range(len(value_counts)))\n",
    "    axes[i].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Добавим значения на столбцы\n",
    "    for j, v in enumerate(value_counts.values):\n",
    "        axes[i].text(j, v, str(v), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Удалим лишний subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Анализ распределений\n",
    "print(\"АНАЛИЗ РАСПРЕДЕЛЕНИЙ ПРИЗНАКОВ:\")\n",
    "print(\"=\"*60)\n",
    "for feature in selected_features:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    value_counts = X[feature].value_counts()\n",
    "    print(f\"  Уникальных значений: {X[feature].nunique()}\")\n",
    "    print(f\"  Наиболее частое значение: {value_counts.index[0]} ({value_counts.iloc[0]} раз, {(value_counts.iloc[0]/len(X)*100):.1f}%)\")\n",
    "    \n",
    "    # Проверка на смещение\n",
    "    max_val = value_counts.max()\n",
    "    min_val = value_counts.min()\n",
    "    ratio = max_val / min_val\n",
    "    if ratio > 3:\n",
    "        print(f\"  ⚠️ Обнаружено сильное смещение (соотношение {ratio:.2f})\")\n",
    "    elif ratio > 2:\n",
    "        print(f\"  ⚠️ Обнаружено умеренное смещение (соотношение {ratio:.2f})\")\n",
    "    else:\n",
    "        print(f\"  ✓ Распределение относительно равномерное\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196323b1",
   "metadata": {},
   "source": [
    "## 8. Зависимость признаков от целевой переменной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем 5 признаков для анализа зависимости от целевой переменной\n",
    "features_for_target = ['Education Level', 'Financial Condition', 'Device', 'Internet Type', 'Class Duration']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(features_for_target):\n",
    "    # Создаем crosstab для визуализации\n",
    "    crosstab = pd.crosstab(X[feature], y, normalize='index') * 100\n",
    "    \n",
    "    # Строим stacked bar chart\n",
    "    crosstab.plot(kind='bar', ax=axes[i], stacked=True, \n",
    "                  color=['#FF6B6B', '#4ECDC4', '#45B7D1'], width=0.8)\n",
    "    axes[i].set_title(f'Зависимость: {feature} → Adaptivity Level', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(feature, fontsize=10)\n",
    "    axes[i].set_ylabel('Процент (%)', fontsize=10)\n",
    "    axes[i].legend(title='Adaptivity Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Удалим лишний subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Анализ взаимосвязей\n",
    "print(\"АНАЛИЗ ВЗАИМОСВЯЗЕЙ С ЦЕЛЕВОЙ ПЕРЕМЕННОЙ:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feature in features_for_target:\n",
    "    print(f\"\\n{feature}:\")\n",
    "    crosstab = pd.crosstab(X[feature], y)\n",
    "    print(crosstab)\n",
    "    \n",
    "    # Проверяем, есть ли значимые различия в распределении\n",
    "    # Используем простую эвристику: если для разных значений признака\n",
    "    # распределение целевой переменной сильно отличается, то признак важен\n",
    "    proportions = pd.crosstab(X[feature], y, normalize='index')\n",
    "    max_diff = proportions.max(axis=1).max() - proportions.min(axis=1).min()\n",
    "    \n",
    "    print(f\"  Максимальная разница в пропорциях: {max_diff:.2f}\")\n",
    "    if max_diff > 0.3:\n",
    "        print(f\"  ✓ Признак имеет сильную взаимосвязь с целевой переменной\")\n",
    "        print(f\"    Можно использовать для прогнозирования\")\n",
    "    elif max_diff > 0.15:\n",
    "        print(f\"  ⚠️ Признак имеет умеренную взаимосвязь с целевой переменной\")\n",
    "        print(f\"    Может быть полезен в комбинации с другими признаками\")\n",
    "    else:\n",
    "        print(f\"  ✗ Признак имеет слабую взаимосвязь с целевой переменной\")\n",
    "        print(f\"    Возможно, не очень полезен для прогнозирования\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f29b89",
   "metadata": {},
   "source": [
    "## 9. Extra: Анализ двух переменных одновременно от целевой переменной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422de5cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m features_for_heatmap = [\u001b[33m'\u001b[39m\u001b[33mEducation Level\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFinancial Condition\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDevice\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mInternet Type\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mClass Duration\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Создадим матрицу корреляций через кодирование\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Создадим копию данных для кодирования\u001b[39;00m\n\u001b[32m      9\u001b[39m data_encoded = data.copy()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Heatmap для категориальных признаков\n",
    "# Выберем несколько признаков для анализа\n",
    "features_for_heatmap = ['Education Level', 'Financial Condition', 'Device', 'Internet Type', 'Class Duration']\n",
    "\n",
    "# Создадим матрицу корреляций через кодирование\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Создадим копию данных для кодирования\n",
    "data_encoded = data.copy()\n",
    "le_dict = {}\n",
    "\n",
    "for col in features_for_heatmap + ['Adaptivity Level']:\n",
    "    le = LabelEncoder()\n",
    "    data_encoded[col] = le.fit_transform(data[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Вычислим корреляционную матрицу\n",
    "corr_matrix = data_encoded[features_for_heatmap + ['Adaptivity Level']].corr()\n",
    "\n",
    "# Построим heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Корреляционная матрица признаков и целевой переменной', \n",
    "         fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Анализ двух переменных одновременно\n",
    "print(\"АНАЛИЗ ДВУХ ПЕРЕМЕННЫХ ОДНОВРЕМЕННО:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Пример: Education Level vs Financial Condition в разрезе целевой переменной\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "target_values = y.unique()\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for idx, target_val in enumerate(target_values):\n",
    "    mask = y == target_val\n",
    "    subset = data[mask]\n",
    "    \n",
    "    crosstab = pd.crosstab(subset['Education Level'], subset['Financial Condition'])\n",
    "    \n",
    "    sns.heatmap(crosstab, annot=True, fmt='d', cmap='YlOrRd', ax=axes[idx],\n",
    "                cbar_kws={'label': 'Количество'})\n",
    "    axes[idx].set_title(f'Adaptivity Level = {target_val}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Financial Condition', fontsize=10)\n",
    "    axes[idx].set_ylabel('Education Level', fontsize=10)\n",
    "\n",
    "plt.suptitle('Education Level vs Financial Condition в разрезе Adaptivity Level', \n",
    "            fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nВыводы:\")\n",
    "print(\"1. Heatmap показывает корреляции между признаками\")\n",
    "print(\"2. Анализ двух переменных одновременно позволяет увидеть сложные взаимосвязи\")\n",
    "print(\"3. Разные уровни адаптивности могут иметь разные паттерны в комбинациях признаков\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

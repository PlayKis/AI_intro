Сделал лабу №1, задача состояла в том, чтобы разобраться с базовыми конструкциями и основами программирования Python. Была проведена пработа с переменными, функциями и классами. В итоге были получены базовые сведения о работе с Python

Сделал лабу №2 по EDA. Был проведен анализ датасета с адаптивностью к онлайн обучению. Я изучил основные переменные, построил гистограммы и диаграммы для поиска взаимосвязей. В итоге выяснил, что все признаки (финансовые возможности, формат обучения, возраст) сильно влияют на адаптивность к онлайн обучению.

Выполнил лабораторную работу №3 по основам машинного обучения. На основе данных об адаптивности студентов к онлайн-обучению я построил модели для предсказания уровня адаптивности (Low, Moderate, High). Для этого я выполнил предобработку данных: разделил выборку на train/test с сохранением пропорций классов, проверил пропуски (их не оказалось), закодировал все категориальные признаки с помощью OneHotEncoder и закодировал целевую переменную. Затем я обучил и сравнил четыре модели: логистическую регрессию с multinomial подходом, дерево решений с подбором оптимальной глубины, k-ближайших соседей с подбором оптимального k и случайный лес. Для оценки использовал метрики Accuracy, F1-score, ROC-AUC (с применением one-vs-rest стратегии), а также построил ROC-кривые, Precision-Recall кривые и матрицы ошибок для каждой модели. В итоге выяснил, что модели "Случайный лес" и "Дерево решений" справились с задачей лучше всего, показав высокое качество на тестовых данных. Это говорит о том, что ансамблевые методы и деревья решений эффективно выявляют сложные нелинейные зависимости между характеристиками студентов (возраст, уровень образования, финансовое положение, тип устройства, интернет-соединение) и их адаптивностью к онлайн-обучению.

Выполнил лабораторную работу №4 по глубокому обучению. На основе того же датасета об адаптивности студентов к онлайн-обучению я построил нейронные сети с использованием PyTorch для предсказания уровня адаптивности. Выполнил предобработку данных аналогично предыдущей работе, затем создал кастомный класс Dataset и DataLoader для работы с PyTorch. Обучил три нейронные сети разной сложности: простую однослойную нейросеть с оптимизатором SGD, нейросеть с одним скрытым слоем (64 нейрона) с оптимизатором Adam и глубокую нейросеть с тремя скрытыми слоями (128-64-32 нейрона) с Adam и dropout для регуляризации. Для каждой модели построил learning curves (кривые обучения), показывающие изменение loss на train и test выборках в зависимости от эпохи обучения. Рассчитал метрику Accuracy для всех моделей на train и test данных. В итоге выяснил, что более сложные архитектуры с несколькими скрытыми слоями и оптимизатором Adam показывают лучшие результаты по сравнению с простой однослойной моделью. Learning curves позволили визуально оценить процесс обучения и выявить признаки переобучения или недообучения. Это демонстрирует, что глубокие нейронные сети способны эффективно извлекать сложные паттерны из данных о характеристиках студентов и их адаптивности к онлайн-обучению.

Выполнил лабораторную работу №5 по классификации изображений с использованием transfer learning. На основе датасета Sports Classification, содержащего изображения 100 различных видов спорта, я построил модель глубокого обучения для многоклассовой классификации изображений. Выполнил полный pipeline работы с изображениями: загрузил данные из CSV файла с путями к изображениям, создал кастомный класс SportsDataset для работы с PyTorch, проверил данные на наличие поврежденных изображений и обработал их. Провел разведочный анализ данных (EDA): проанализировал распределение классов, оценил дисбаланс данных, построил гистограммы и барчарты для визуализации распределения. Настроил аугментации данных для улучшения обобщающей способности модели: RandomResizedCrop для устойчивости к масштабам, RandomHorizontalFlip для симметричных объектов, RandomRotation для устойчивости к поворотам и ColorJitter для устойчивости к изменениям освещения. Применил transfer learning, используя предобученную модель ResNet18 с весами ImageNet, заменил выходной слой под 100 классов и обучил модель с оптимизатором AdamW и функцией потерь CrossEntropyLoss. В процессе обучения логировал train loss/accuracy и validation loss/accuracy по эпохам, сохранил лучшую модель по валидационной точности. Рассчитал метрики качества на train и validation выборках: Accuracy, Precision, Recall, F1-score (macro и micro average), построил матрицы ошибок (Confusion Matrix) и ROC-кривые для многоклассовой классификации (one-vs-rest стратегия). Проанализировал результаты обучения: построил learning curves для визуализации процесса обучения, выявил признаки переобучения, определил классы, которые путаются чаще всего, и дал рекомендации по улучшению (усиление аугментаций, использование class weights при дисбалансе, fine-tuning с заморозкой слоев). Визуализировал предсказания модели на валидационной выборке, показав не менее 10 изображений с предсказанными и истинными классами, пометив корректные и ошибочные предсказания. В итоге выяснил, что transfer learning с предобученной ResNet18 эффективно справляется с задачей классификации спортивных изображений, демонстрируя способность извлекать сложные визуальные паттерны из изображений различных видов спорта. Это демонстрирует мощь transfer learning для задач компьютерного зрения, когда предобученные на больших датасетах модели могут быть успешно адаптированы для специфических задач с относительно небольшим количеством данных.
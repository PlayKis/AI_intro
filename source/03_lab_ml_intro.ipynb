{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9520d2",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3\n",
    "\n",
    "ФИО:   \n",
    "Группа: \n",
    "\n",
    "Отправлять можно следующими способами:\n",
    "1. Запушить этот ноутбук в GitHub в репозиторий, где у вас лежат ноутбуки с лабами\n",
    "\n",
    "Deadlines:\n",
    "- Занятие №6 в семестре\n",
    "\n",
    "Что необходимо сделать:  \n",
    "- Обучить различного рода модели машинного обучения и сравнить их между собой  \n",
    "\n",
    "---\n",
    "## Читайте задание внимательно\n",
    "\n",
    "Исходные данные:\n",
    "1. В [табличке](https://docs.google.com/spreadsheets/d/1NOE0D4JQgD6LbvUqWboUI1TFj4P87ugbqUTDquxlGEI/edit?usp=sharing) необходимо узнать название своего датасета \n",
    "2. Скачать нужны вам данные можно в [Google Drive](https://drive.google.com/drive/folders/1sbsjBsJ_ln0XgXCI9R6s17pvyvApgcwF?usp=sharing)\n",
    "  \n",
    "---\n",
    "Теперь по пунктам, что я от вас жду:  \n",
    "1. Загрузить необходимые данные к себе и считать (read) их в переменную.\n",
    "2. Понять, у вас задача классификации (бинарной или многоклассовой) или регрессии (**если у вас многоклассовая классификация, прочтите P.S.S. внизу**).\n",
    "3. Сделать предобработку данных:  \n",
    "     1. Разделить выборку на тренировочную (train) и тестовую (test). _Обратите внимание, что обучать скейлеры и определять, какими значениями вы будете заполнять пропуски, вы будете на train выборке, а применять и на train, и на test_.\n",
    "     2. Проверить пропуски в данных. Если они есть, заполнить одной из стратегий, предложенных в ноутбуке для семинара №3. P.S. Для численных и категориальных переменных будут разные стратегии.\n",
    "     3. Отнормировать численные переменные (`StandardScaler`, `MinMaxScaler`).\n",
    "     4. Закодировать категориальные признаки по одной из стратегий.\n",
    "4. Обучить на тренировочном множестве:\n",
    "     1. Линейную модель (`LogisticRegression`, `LinearRegression`)\n",
    "     2. Деревянную модель (`DecisionTreeClassifier`, `DecisionTreeRegressor`) (тут советую попробовать разные глубины деревьев)\n",
    "     3. K-ближайших соседей (`KNeighborsClassifier`, `KNeighborsRegressor`) (тут тоже есть смысл попробовать разные `k`)\n",
    "     4. Случайный лес (`RandomForestClassifier`, `RandomForestRegressor`) \n",
    "5. Посчитайте метрики на train и test множествах:\n",
    "     1. Для задачи классификации -- Accuracy, ROC-AUC (график + значение), PR-кривую (график), F1-score\n",
    "     2. Для задачи регрессии -- MAE, RMSE, MAPE\n",
    "6. Сравните метрики относительно train/test, так и относительно разных моделей. Ответьте на следующие вопросы:\n",
    "     1. Какая модель справилась лучше с поставленной задачей?\n",
    "     2. Имеет ли место переобучение?\n",
    "     3. Имеет ли место недообучение?\n",
    "     4. Как можно улучшить метрики моделей?\n",
    "\n",
    "---\n",
    "P.S.  \n",
    "Просьба -- делать каждое задание в отдельных ячейках и с отдельными заголовками (как пункт 1 и 2 в этом ноутбуке) типа  \n",
    "- Заголовок\n",
    "- Ячейки с кодом\n",
    "- Другой заголовок\n",
    "- Другие ячейки с кодом\n",
    "\n",
    "P.S.S.  \n",
    "Если вам повезло с многоклассовой классификацией, вам будет необходимо понять, умеет ли алгоритм работать с несколькими классами одновременно (обычно они не умеют). Поэтому вам может понадобиться такая штука, как OneVsRestClassifier ([ссылка](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier)), но советую ознакомиться с этой [страницей](https://scikit-learn.org/stable/modules/multiclass.html), здесь представлена более полная информация."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51062",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406597a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, \n",
    "                            roc_curve, precision_recall_curve, \n",
    "                            classification_report, confusion_matrix)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('students_adaptability_level_online_education.csv')\n",
    "print(f\"Размер датасета: {data.shape}\")\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d119028",
   "metadata": {},
   "source": [
    "## 2. Определение типа задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92464d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Adaptivity Level', axis=1)\n",
    "y = data['Adaptivity Level']\n",
    "\n",
    "print(\"Информация о задаче:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Количество признаков: {X.shape[1]}\")\n",
    "print(f\"Количество образцов: {X.shape[0]}\")\n",
    "print(f\"\\nЦелевая переменная: {y.name}\")\n",
    "print(f\"Уникальные значения целевой переменной: {y.unique()}\")\n",
    "print(f\"Количество классов: {y.nunique()}\")\n",
    "print(f\"\\nРаспределение классов:\")\n",
    "print(y.value_counts().sort_index())\n",
    "\n",
    "if y.nunique() == 2:\n",
    "    task_type = \"Бинарная классификация\"\n",
    "elif y.nunique() > 2:\n",
    "    task_type = \"Многоклассовая классификация\"\n",
    "else:\n",
    "    if pd.api.types.is_numeric_dtype(y):\n",
    "        task_type = \"Регрессия\"\n",
    "    else:\n",
    "        task_type = \"Классификация\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ТИП ЗАДАЧИ: {task_type}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if task_type == \"Многоклассовая классификация\":\n",
    "    print(\"\\n⚠️ Это многоклассовая классификация!\")\n",
    "    print(\"Некоторые алгоритмы могут потребовать OneVsRestClassifier или другую стратегию.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34931f43",
   "metadata": {},
   "source": [
    "## 3. Предобработка данных\n",
    "\n",
    "### 3.1. Разделение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a611d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер тренировочной выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"\\nРаспределение классов в train:\")\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\nРаспределение классов в test:\")\n",
    "print(y_test.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7e01c",
   "metadata": {},
   "source": [
    "### 3.2. Проверка и обработка пропущенных значений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf0de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Пропуски в тренировочной выборке:\")\n",
    "print(\"=\"*60)\n",
    "missing_train = X_train.isnull().sum()\n",
    "if missing_train.sum() > 0:\n",
    "    print(missing_train[missing_train > 0])\n",
    "else:\n",
    "    print(\"✓ Пропусков не обнаружено!\")\n",
    "\n",
    "print(\"\\nПропуски в тестовой выборке:\")\n",
    "print(\"=\"*60)\n",
    "missing_test = X_test.isnull().sum()\n",
    "if missing_test.sum() > 0:\n",
    "    print(missing_test[missing_test > 0])\n",
    "else:\n",
    "    print(\"✓ Пропусков не обнаружено!\")\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nКатегориальные признаки ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Численные признаки ({len(numerical_cols)}): {numerical_cols}\")\n",
    "\n",
    "if missing_train.sum() > 0:\n",
    "    if len(categorical_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X_train[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\n",
    "        X_test[categorical_cols] = cat_imputer.transform(X_test[categorical_cols])\n",
    "    \n",
    "    if len(numerical_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        X_train[numerical_cols] = num_imputer.fit_transform(X_train[numerical_cols])\n",
    "        X_test[numerical_cols] = num_imputer.transform(X_test[numerical_cols])\n",
    "    \n",
    "    print(\"\\n✓ Пропуски заполнены!\")\n",
    "else:\n",
    "    print(\"\\n✓ Пропусков нет, заполнение не требуется.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f9e9d",
   "metadata": {},
   "source": [
    "### 3.3. Нормализация численных признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(numerical_cols) > 0:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "    X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "    \n",
    "    print(\"✓ Численные признаки нормализованы с помощью StandardScaler\")\n",
    "else:\n",
    "    print(\"ℹ️ Численных признаков нет, нормализация не требуется\")\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea31b7",
   "metadata": {},
   "source": [
    "### 3.4. Кодирование категориальных признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "X_train_encoded = pd.DataFrame(\n",
    "    ohe.fit_transform(X_train_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train_scaled.index\n",
    ")\n",
    "\n",
    "X_test_encoded = pd.DataFrame(\n",
    "    ohe.transform(X_test_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test_scaled.index\n",
    ")\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    X_train_final = pd.concat([X_train_encoded, X_train_scaled[numerical_cols]], axis=1)\n",
    "    X_test_final = pd.concat([X_test_encoded, X_test_scaled[numerical_cols]], axis=1)\n",
    "else:\n",
    "    X_train_final = X_train_encoded\n",
    "    X_test_final = X_test_encoded\n",
    "\n",
    "print(f\"Размерность признаков после кодирования:\")\n",
    "print(f\"Train: {X_train_final.shape}\")\n",
    "print(f\"Test: {X_test_final.shape}\")\n",
    "print(f\"\\n✓ Категориальные признаки закодированы с помощью OneHotEncoder\")\n",
    "\n",
    "le_y = LabelEncoder()\n",
    "y_train_encoded = le_y.fit_transform(y_train)\n",
    "y_test_encoded = le_y.transform(y_test)\n",
    "\n",
    "print(f\"\\nКодирование целевой переменной:\")\n",
    "for i, label in enumerate(le_y.classes_):\n",
    "    print(f\"  {label} -> {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14768059",
   "metadata": {},
   "source": [
    "## 4. Обучение моделей\n",
    "\n",
    "### 4.1. Линейная модель (LogisticRegression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "lr_model.fit(X_train_final, y_train_encoded)\n",
    "\n",
    "y_train_pred_lr = lr_model.predict(X_train_final)\n",
    "y_test_pred_lr = lr_model.predict(X_test_final)\n",
    "\n",
    "y_train_proba_lr = lr_model.predict_proba(X_train_final)\n",
    "y_test_proba_lr = lr_model.predict_proba(X_test_final)\n",
    "\n",
    "print(\"✓ LogisticRegression обучена\")\n",
    "print(f\"Точность на train: {accuracy_score(y_train_encoded, y_train_pred_lr):.4f}\")\n",
    "print(f\"Точность на test: {accuracy_score(y_test_encoded, y_test_pred_lr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1ae6b",
   "metadata": {},
   "source": [
    "### 4.2. Деревянная модель (DecisionTreeClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ae024",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [3, 5, 10, 15, 20, None]\n",
    "dt_models = {}\n",
    "dt_results = {}\n",
    "\n",
    "for depth in depths:\n",
    "    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    dt_model.fit(X_train_final, y_train_encoded)\n",
    "    \n",
    "    y_train_pred = dt_model.predict(X_train_final)\n",
    "    y_test_pred = dt_model.predict(X_test_final)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train_encoded, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
    "    \n",
    "    dt_models[depth] = dt_model\n",
    "    dt_results[depth] = {'train_acc': train_acc, 'test_acc': test_acc}\n",
    "    \n",
    "    print(f\"Глубина {depth if depth else 'без ограничений'}: \"\n",
    "          f\"Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "\n",
    "best_depth = max(dt_results.keys(), key=lambda k: dt_results[k]['test_acc'])\n",
    "dt_model = dt_models[best_depth]\n",
    "\n",
    "y_train_pred_dt = dt_model.predict(X_train_final)\n",
    "y_test_pred_dt = dt_model.predict(X_test_final)\n",
    "y_train_proba_dt = dt_model.predict_proba(X_train_final)\n",
    "y_test_proba_dt = dt_model.predict_proba(X_test_final)\n",
    "\n",
    "print(f\"\\n✓ Лучшая DecisionTree с глубиной {best_depth if best_depth else 'без ограничений'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce2dd3",
   "metadata": {},
   "source": [
    "### 4.3. K-ближайших соседей (KNeighborsClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [3, 5, 7, 10, 15, 20]\n",
    "knn_models = {}\n",
    "knn_results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(X_train_final, y_train_encoded)\n",
    "    \n",
    "    y_train_pred = knn_model.predict(X_train_final)\n",
    "    y_test_pred = knn_model.predict(X_test_final)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train_encoded, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
    "    \n",
    "    knn_models[k] = knn_model\n",
    "    knn_results[k] = {'train_acc': train_acc, 'test_acc': test_acc}\n",
    "    \n",
    "    print(f\"k = {k}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "\n",
    "best_k = max(knn_results.keys(), key=lambda k: knn_results[k]['test_acc'])\n",
    "knn_model = knn_models[best_k]\n",
    "\n",
    "y_train_pred_knn = knn_model.predict(X_train_final)\n",
    "y_test_pred_knn = knn_model.predict(X_test_final)\n",
    "y_train_proba_knn = knn_model.predict_proba(X_train_final)\n",
    "y_test_proba_knn = knn_model.predict_proba(X_test_final)\n",
    "\n",
    "print(f\"\\n✓ Лучший KNN с k = {best_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83751d3",
   "metadata": {},
   "source": [
    "### 4.4. Случайный лес (RandomForestClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_final, y_train_encoded)\n",
    "\n",
    "y_train_pred_rf = rf_model.predict(X_train_final)\n",
    "y_test_pred_rf = rf_model.predict(X_test_final)\n",
    "y_train_proba_rf = rf_model.predict_proba(X_train_final)\n",
    "y_test_proba_rf = rf_model.predict_proba(X_test_final)\n",
    "\n",
    "print(\"✓ RandomForestClassifier обучена\")\n",
    "print(f\"Точность на train: {accuracy_score(y_train_encoded, y_train_pred_rf):.4f}\")\n",
    "print(f\"Точность на test: {accuracy_score(y_test_encoded, y_test_pred_rf):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51b523",
   "metadata": {},
   "source": [
    "## 5. Расчет метрик\n",
    "\n",
    "### 5.1. Accuracy и F1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': (y_train_pred_lr, y_test_pred_lr, y_train_proba_lr, y_test_proba_lr),\n",
    "    'DecisionTree': (y_train_pred_dt, y_test_pred_dt, y_train_proba_dt, y_test_proba_dt),\n",
    "    'KNN': (y_train_pred_knn, y_test_pred_knn, y_train_proba_knn, y_test_proba_knn),\n",
    "    'RandomForest': (y_train_pred_rf, y_test_pred_rf, y_train_proba_rf, y_test_proba_rf)\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train Accuracy', 'Test Accuracy', \n",
    "                                   'Train F1', 'Test F1', 'Train ROC-AUC', 'Test ROC-AUC'])\n",
    "\n",
    "for model_name, (y_train_pred, y_test_pred, y_train_proba, y_test_proba) in models.items():\n",
    "    train_acc = accuracy_score(y_train_encoded, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
    "    train_f1 = f1_score(y_train_encoded, y_train_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test_encoded, y_test_pred, average='weighted')\n",
    "    \n",
    "    train_roc = roc_auc_score(y_train_encoded, y_train_proba, multi_class='ovr', average='weighted')\n",
    "    test_roc = roc_auc_score(y_test_encoded, y_test_proba, multi_class='ovr', average='weighted')\n",
    "    \n",
    "    results_df = pd.concat([results_df, pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'Train Accuracy': [train_acc],\n",
    "        'Test Accuracy': [test_acc],\n",
    "        'Train F1': [train_f1],\n",
    "        'Test F1': [test_f1],\n",
    "        'Train ROC-AUC': [train_roc],\n",
    "        'Test ROC-AUC': [test_roc]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "print(\"МЕТРИКИ МОДЕЛЕЙ:\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e0dc8f",
   "metadata": {},
   "source": [
    "### 5.2. ROC-кривые\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e318843",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, (_, _, _, y_test_proba)) in enumerate(models.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for class_idx, class_name in enumerate(le_y.classes_):\n",
    "        y_test_binary = (y_test_encoded == class_idx).astype(int)\n",
    "        y_proba_class = y_test_proba[:, class_idx]\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_test_binary, y_proba_class)\n",
    "        roc_auc = roc_auc_score(y_test_binary, y_proba_class)\n",
    "        \n",
    "        ax.plot(fpr, tpr, label=f'{class_name} (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=11)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=11)\n",
    "    ax.set_title(f'ROC-кривые: {model_name}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='lower right', fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC-AUC (weighted average) на тестовой выборке:\")\n",
    "print(\"=\"*60)\n",
    "for model_name, (_, _, _, y_test_proba) in models.items():\n",
    "    roc_auc = roc_auc_score(y_test_encoded, y_test_proba, multi_class='ovr', average='weighted')\n",
    "    print(f\"{model_name}: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b7f1a",
   "metadata": {},
   "source": [
    "### 5.3. Precision-Recall кривые\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc778bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, (_, _, _, y_test_proba)) in enumerate(models.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for class_idx, class_name in enumerate(le_y.classes_):\n",
    "        y_test_binary = (y_test_encoded == class_idx).astype(int)\n",
    "        y_proba_class = y_test_proba[:, class_idx]\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_test_binary, y_proba_class)\n",
    "        \n",
    "        ax.plot(recall, precision, label=f'{class_name}', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Recall', fontsize=11)\n",
    "    ax.set_ylabel('Precision', fontsize=11)\n",
    "    ax.set_title(f'Precision-Recall кривые: {model_name}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='lower left', fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f17353",
   "metadata": {},
   "source": [
    "### 5.4. Матрицы ошибок (Confusion Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_name, (_, y_test_pred, _, _)) in enumerate(models.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    cm = confusion_matrix(y_test_encoded, y_test_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=le_y.classes_, yticklabels=le_y.classes_)\n",
    "    ax.set_xlabel('Предсказанный класс', fontsize=11)\n",
    "    ax.set_ylabel('Истинный класс', fontsize=11)\n",
    "    ax.set_title(f'Матрица ошибок: {model_name}', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66e1b1",
   "metadata": {},
   "source": [
    "### 5.5. Детальные отчеты по классификации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974796d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, (_, y_test_pred, _, _) in models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ОТЧЕТ ПО КЛАССИФИКАЦИИ: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(classification_report(y_test_encoded, y_test_pred, \n",
    "                                target_names=le_y.classes_, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e1a75",
   "metadata": {},
   "source": [
    "## 6. Сравнение моделей и выводы\n",
    "\n",
    "### 6.1. Визуализация сравнения метрик\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ddcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, results_df['Train Accuracy'], width, label='Train', alpha=0.8)\n",
    "ax1.bar(x + width/2, results_df['Test Accuracy'], width, label='Test', alpha=0.8)\n",
    "ax1.set_xlabel('Модели', fontsize=11)\n",
    "ax1.set_ylabel('Accuracy', fontsize=11)\n",
    "ax1.set_title('Сравнение Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(x - width/2, results_df['Train F1'], width, label='Train', alpha=0.8)\n",
    "ax2.bar(x + width/2, results_df['Test F1'], width, label='Test', alpha=0.8)\n",
    "ax2.set_xlabel('Модели', fontsize=11)\n",
    "ax2.set_ylabel('F1-score', fontsize=11)\n",
    "ax2.set_title('Сравнение F1-score', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(x - width/2, results_df['Train ROC-AUC'], width, label='Train', alpha=0.8)\n",
    "ax3.bar(x + width/2, results_df['Test ROC-AUC'], width, label='Test', alpha=0.8)\n",
    "ax3.set_xlabel('Модели', fontsize=11)\n",
    "ax3.set_ylabel('ROC-AUC', fontsize=11)\n",
    "ax3.set_title('Сравнение ROC-AUC', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "overfitting = results_df['Train Accuracy'] - results_df['Test Accuracy']\n",
    "ax4.bar(x, overfitting, alpha=0.8, color='red')\n",
    "ax4.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "ax4.set_xlabel('Модели', fontsize=11)\n",
    "ax4.set_ylabel('Разница (Train - Test)', fontsize=11)\n",
    "ax4.set_title('Переобучение (разница Accuracy)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb73237",
   "metadata": {},
   "source": [
    "### 6.2. Анализ результатов и ответы на вопросы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4236ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"АНАЛИЗ РЕЗУЛЬТАТОВ И ВЫВОДЫ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model_idx = results_df['Test Accuracy'].idxmax()\n",
    "best_model = results_df.loc[best_model_idx, 'Model']\n",
    "best_acc = results_df.loc[best_model_idx, 'Test Accuracy']\n",
    "\n",
    "print(f\"\\n1. Какая модель справилась лучше с поставленной задачей?\")\n",
    "print(f\"   ✓ Лучшая модель: {best_model}\")\n",
    "print(f\"   ✓ Test Accuracy: {best_acc:.4f}\")\n",
    "print(f\"   ✓ Test F1-score: {results_df.loc[best_model_idx, 'Test F1']:.4f}\")\n",
    "print(f\"   ✓ Test ROC-AUC: {results_df.loc[best_model_idx, 'Test ROC-AUC']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. Имеет ли место переобучение?\")\n",
    "overfitting_threshold = 0.05\n",
    "for idx, row in results_df.iterrows():\n",
    "    diff = row['Train Accuracy'] - row['Test Accuracy']\n",
    "    if diff > overfitting_threshold:\n",
    "        print(f\"   ⚠️ {row['Model']}: Переобучение обнаружено (разница = {diff:.4f})\")\n",
    "    elif diff < -0.01:\n",
    "        print(f\"   ℹ️ {row['Model']}: Небольшое недообучение (разница = {diff:.4f})\")\n",
    "    else:\n",
    "        print(f\"   ✓ {row['Model']}: Переобучения нет (разница = {diff:.4f})\")\n",
    "\n",
    "print(f\"\\n3. Имеет ли место недообучение?\")\n",
    "for idx, row in results_df.iterrows():\n",
    "    if row['Test Accuracy'] < 0.6:\n",
    "        print(f\"   ⚠️ {row['Model']}: Возможно недообучение (Test Accuracy = {row['Test Accuracy']:.4f})\")\n",
    "    else:\n",
    "        print(f\"   ✓ {row['Model']}: Недообучения нет (Test Accuracy = {row['Test Accuracy']:.4f})\")\n",
    "\n",
    "print(f\"\\n4. Как можно улучшить метрики моделей?\")\n",
    "print(\"   Рекомендации:\")\n",
    "print(\"   • Для DecisionTree:\")\n",
    "print(\"     - Попробовать другие значения max_depth, min_samples_split, min_samples_leaf\")\n",
    "print(\"     - Использовать GridSearchCV для подбора гиперпараметров\")\n",
    "print(\"   • Для KNN:\")\n",
    "print(\"     - Попробовать другие метрики расстояния (manhattan, minkowski)\")\n",
    "print(\"     - Использовать веса (weights='distance')\")\n",
    "print(\"   • Для RandomForest:\")\n",
    "print(\"     - Увеличить n_estimators\")\n",
    "print(\"     - Настроить max_depth, min_samples_split\")\n",
    "print(\"     - Попробовать другие критерии (entropy вместо gini)\")\n",
    "print(\"   • Для LogisticRegression:\")\n",
    "print(\"     - Попробовать разные регуляризации (L1, L2)\")\n",
    "print(\"     - Настроить параметр C\")\n",
    "print(\"   • Общие рекомендации:\")\n",
    "print(\"     - Использовать кросс-валидацию для более надежной оценки\")\n",
    "print(\"     - Попробовать feature engineering (создание новых признаков)\")\n",
    "print(\"     - Использовать ансамбли моделей\")\n",
    "print(\"     - Попробовать другие алгоритмы (XGBoost, LightGBM, SVM)\")\n",
    "print(\"     - Использовать SMOTE для балансировки классов (если есть дисбаланс)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn-ml-bachelor-2024-venv",
   "language": "python",
   "name": "nn-ml-bachelor-2024-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
